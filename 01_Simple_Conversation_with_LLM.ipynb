{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTzBUFWQ-OWj"
      },
      "source": [
        "# Create a Simple Q&A with LLM\n",
        "\n",
        "Notebook Focus \n",
        "- Import Required Libraries\n",
        "- Load Creds using yaml file\n",
        "- Write a simple Q&A chain to LLM\n",
        "- Adding multiple contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1KvMtf54l0d"
      },
      "source": [
        "## Install OpenAI and LangChain Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evPp14fy258",
        "outputId": "4bc03b40-0618-484a-cf4f-16f849da45bd"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.1.12\n",
        "!pip install langchain-openai==0.0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwGjVWK4q6F"
      },
      "source": [
        "## Load OpenAI API Credentials\n",
        "\n",
        "Save the key in 'api_credentials.yml'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5e1HqI56y7t3"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ryheOZuXxa41"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "with open('api_credentials.yml', 'r') as file:\n",
        "    api_creds = yaml.safe_load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZs7ts6NzADJ",
        "outputId": "9d4c28f9-a9df-4493-f792-17e96a7557f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['openai_key'])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api_creds.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kDe44J0N0NcC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = api_creds['openai_key']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDWhgxCy5bA6"
      },
      "source": [
        "## Load ChatGPT LLM Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9GYhyRFRuJXG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mY2bapqfuWq1"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.0) # choose the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJrIiENwxMx9"
      },
      "source": [
        "## Simple Q&A Prompting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Evdag0KuOXo",
        "outputId": "25ef54a0-8b82-49ee-f109-783b0bc68ae3"
      },
      "outputs": [],
      "source": [
        "PROMPT = \"Write a haiku poem on  {topic}\" # prompt is the Question you want to ask. And you can replace the {topic} which is dynamic variable\n",
        "prompt = ChatPromptTemplate.from_template(PROMPT) # creating a template for Prompt\n",
        "\n",
        "chain = (prompt |  model )  # passing the Prompt --> Model \n",
        "\n",
        "response = chain.invoke({\"topic\": \"India\"}) # Dynamically passing 'India' as variable'\n",
        "print(response.content) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Tp84pgKXvKuY"
      },
      "outputs": [],
      "source": [
        "# Lets loop to ask multiple Contents \n",
        "topics = [{'topic': 'Rivers'}, {'topic': 'Libraries'}]\n",
        "responses = chain.map().invoke(topics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QePjecVqviA3",
        "outputId": "a9b359b1-3ef4-40d3-e3ee-cafdae7ab00a"
      },
      "outputs": [],
      "source": [
        "for response in responses:\n",
        "  print(response.content)\n",
        "  print('-----')\n",
        "  print('\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
